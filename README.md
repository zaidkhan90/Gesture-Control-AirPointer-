# 🖱️ Gesture-Controlled AirPointer

A futuristic gesture-controlled AirPointer that lets users control their cursor **without touching a mouse or screen**. Built using computer vision and hand tracking, this system turns your fingers into a natural input device — making interaction touchless, intuitive, and fun!

## 🚀 Project Highlights

- ✋ **Hand Gesture Recognition** using real-time computer vision
- 🧠 **AI-powered fingertip tracking** for smooth cursor movement
- 🖥️ Control system UI without keyboard or mouse
- 💡 Built with a focus on accessibility, innovation, and user experience
- 🧰 Lightweight, fast, and works on low-spec systems

## 💼 Why This Project Matters

Touchless interfaces are the future — in a world where hygiene, accessibility, and convenience matter more than ever, this project aims to **redefine how we interact with machines**. It has potential applications in:

- Smart classrooms and presentations
- Assistive technology for people with mobility impairments
- Interactive kiosks and displays
- AR/VR gesture-based navigation systems

## 🛠️ Tech Stack

- Python
- OpenCV
- Mediapipe (for hand tracking)
- PyAutoGUI (for controlling mouse)

## 📸 Demo

> _Add a video or GIF of the project in action here to really wow viewers_

## 📁 How to Run Locally

```bash
git clone https://github.com/zaidkhan90/Gesture-Control-AirPointer-.git
cd Gesture-Control-AirPointer-
pip install -r requirements.txt
python airpointer.py
``
